{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_WDL_Label.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaXLJ8xVlsrU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_paths=glob.glob('/content/drive/MyDrive/WDL/police_complaints/*.csv')\n",
        "\n",
        "file_paths=glob.glob('/content/drive/MyDrive/WDL/police_complaints/*.csv')\n",
        "\n",
        "concat_data = []\n",
        "for file in file_paths:\n",
        "      df = pd.read_csv(file, sep=',')\n",
        "      df['Timestamp'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
        "      concat_data.append(df)\n",
        "df_final = pd.concat(concat_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YlPNZCh7ND2"
      },
      "source": [
        "filter = ['Facilities disturbances', 'Disturbing noises', 'Youth aggregation']\n",
        "\n",
        "df_filtered = df_final.loc[df_final['Criminal sub-category'].isin(filter)].reset_index()\n",
        "\n",
        "#San Salvario district 8\n",
        "\n",
        "df_filtered = df_filtered[df_filtered['District'] == 8.0 ]\n",
        "\n",
        "df_filtered['Localization'] = df_filtered['Localization'].str.lower().str.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDb1bKpyQYDN"
      },
      "source": [
        "file_paths=glob.glob('/content/drive/MyDrive/WDL/noise_data/*.csv')\n",
        "\n",
        "\n",
        "sensor_list = pd.read_csv('/content/drive/MyDrive/WDL/noise_sensor_list.csv', sep = ';')\n",
        "sensor_list['Sensor_ID'] = ['C1', 'C2', 'C3', 'C4', 'C5']\n",
        "\n",
        "sensor_list['Lat'] = sensor_list['Lat'].str.replace(',', '.').astype(float)\n",
        "sensor_list['Long'] = sensor_list['Long'].str.replace(',', '.').astype(float)\n",
        "\n",
        "\n",
        "def load_noise_data(file_paths, sensor_list):\n",
        "    \"\"\"\n",
        "    Function for loading noise data into the correct format\n",
        "    \"\"\"\n",
        "    concat_data = []\n",
        "    for file in file_paths:\n",
        "        df = pd.read_csv(file, header=8, sep=';')\n",
        "        df = df.melt(id_vars=['Data', 'Ora'])\n",
        "        df['Timestamp'] = pd.to_datetime(df['Data'] + ' ' + df['Ora'])\n",
        "        df.columns = ['Date', 'Time', 'Sensor_ID', 'Intensity', 'Timestamp']\n",
        "\n",
        "        concat_data.append(df)\n",
        "\n",
        "    concat_df = pd.concat(concat_data)\n",
        "\n",
        "    output = concat_df.merge(sensor_list, on=['Sensor_ID'])\n",
        "    return output[['Timestamp', 'Sensor_ID', 'Intensity', 'address', 'Lat', 'Long']]\n",
        "\n",
        "data = load_noise_data(file_paths, sensor_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMFvJ523Qe9r"
      },
      "source": [
        "localization_address_mapping = {\n",
        "   'principe tommaso/(via)':  'Via Principe Tommaso, 18bis Torino',\n",
        "   'baretti/giuseppe (via)': 'Via Principe Tommaso angolo via Baretti Torino',\n",
        "   'marconi/guglielmo (corso)' : 'Corso Marconi, 27 Torino',\n",
        "   'saluzzo/(largo)': 'Largo Saluzzo Torino',\n",
        "   'saluzzo/(via)': 'Via Saluzzo, 26 Torino'\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyrLFKdnMh5T"
      },
      "source": [
        "df_filtered['address'] = df_filtered['Localization'].map(localization_address_mapping)\n",
        "tmp = df_filtered.merge(data, on=['address'])\n",
        "\n",
        "tmp['Timestamp_x'] = pd.to_datetime(tmp['Timestamp_x'])\n",
        "tmp['Timestamp_y'] = pd.to_datetime(tmp['Timestamp_y'])\n",
        "\n",
        "tmp['day_difference'] = (tmp['Timestamp_x'] - tmp['Timestamp_y']).dt.days\n",
        "\n",
        "def label (row):\n",
        "   if row['day_difference'] == 1 or row['day_difference'] == 0 :\n",
        "      return 1\n",
        "   else:\n",
        "      return 0\n",
        "\n",
        "tmp['label'] = tmp.apply(label, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}