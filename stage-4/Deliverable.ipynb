{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96rLCQLdXuUW"
   },
   "source": [
    "# Data Sources and Files\n",
    "\n",
    "We use the following data sources and/or files:\n",
    " 1) \"reverse_loc.pickle\": a .PICKLE file with the reversed-coordinates (*i.e.*, the name of the parish, city and district related to a given pair of coordinates)\n",
    " \n",
    " 2) \"df_reverse_coords.csv\": a .CSV file with the reversed-coordinates (*i.e.*, the name of the parish, city and district related to a given pair of coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6p8-jo3JB6V"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVYHf0LiXuUY"
   },
   "source": [
    "## What is the problem?\n",
    "As stated by the challenge provider in the official document, \"*cities are flooded by countless outdoor advertising panels, often with a poor distribution*\". Hence, we acknowledge that these visual aspects are crucial in the urban planning process since each plan choice can generate obstruction of urban elements, thus producing adverse effects on the city’s image.\n",
    "\n",
    "## How do we relate this problem with the United Nations' Sustainable Development Goals (SDGs)?\n",
    "Once again, we started by looking at the official document given by the challenge provider, which establishes a connection between this challenge and the **11th UN Sustainable Goal - Sustainable Cities and Communities**. From an attentive look at the scope of this 11th SDG, we can conclude that this is, somehow, related to the topic of \"*Sustainable cities and human settlements*\" (please refer to [https://sdgs.un.org/topics/sustainable-cities-and-human-settlements](https://sdgs.un.org/topics/sustainable-cities-and-human-settlements)). Since it is expected that the number of people in cities will grow significantly by 2050, it is of utmost importance that policy- and decision-makers define a sustainable strategy to assure that their cities have the right infrastructures to keep up with this development rate. We highlight two important ideas:\n",
    " - *Improving human settlements management*; \n",
    " - *Promoting sustainable land-use planning and management*.\n",
    "\n",
    "The ideas above are directly related to the proper organisation of outdoor advertising panels in cities in the sense that careful management may contribute to an increase of visual quality of streets and roads but also allows to increase the focus on the message and the announcement that the panel intends to transmit. Therefore, we agree that reducing the outdoor advertising visual impact in cities will contribute to minimising the reduction of the audience of the outdoor ad sector, thus improving the visual environment of cities and the sustainability of outdoor advertising activity.\n",
    "\n",
    "\n",
    "## How do we propose to solve this problem?\n",
    "We developed a metaheuristics-based algorithm (local/neighbourhood search) that optimises the outdoor-billboard density and the total number of views (*i.e.*, the number of outdoor billboards in a given radius). We start by creating neighbour solutions through swap operations in which we change the coordinates of a given billboard and assess the impact on hour fitness function, which takes this variable into account.\n",
    "\n",
    "In the end, we are capable of proposing an alternative layout for the billboard location without needing to remove billboards. Why did we not want to remove billboards? Well, we do not know if by removing a billboard we are jeopardising the business of a given company. Therefore, we tried to keep our problem approach as simples as possible and thinking about the stakeholders as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8GXmbdQXuUY"
   },
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4jIU2Ec8XuUZ"
   },
   "outputs": [],
   "source": [
    "# !pip install pyshp\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import shapefile\n",
    "from geopy import distance\n",
    "from folium.plugins import FastMarkerCluster\n",
    "import folium\n",
    "import branca.colormap as cm \n",
    "from collections import defaultdict\n",
    "from folium.plugins import HeatMap\n",
    "from geopy.distance import distance\n",
    "\n",
    "KMS_PER_RADIAN = 6371.0088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dtlzal3UXuUZ"
   },
   "outputs": [],
   "source": [
    "def read_shapefile(shp_path):\n",
    "    \"\"\"\n",
    "    Read a shapefile into a Pandas dataframe with a 'coords' column holding\n",
    "    the geometry information. This uses the pyshp package\n",
    "    \"\"\"\n",
    "\n",
    "    #read file, parse out the records and shapes\n",
    "    sf = shapefile.Reader(shp_path)\n",
    "    fields = [x[0] for x in sf.fields][1:]\n",
    "    records = sf.records()\n",
    "    shps = [s.points for s in sf.shapes()]\n",
    "\n",
    "    #write into a dataframe\n",
    "    df = pd.DataFrame(columns=fields, data=records)\n",
    "    df = df.assign(coords=shps)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbDj5ERpJB6W",
    "outputId": "60bef54f-c043-47cc-9397-390533172598"
   },
   "outputs": [],
   "source": [
    "# Read shapefile with the ourdoor inventory\n",
    "\n",
    "df = read_shapefile('data/outdoor_inventory/Outdoor_Inventory_AV.shp')\n",
    "\n",
    "# Read pickle file containing mapping between coordinates and location (done in appendix)\n",
    "reverse_coords_list = pd.read_pickle('data/reverse_loc.pickle')\n",
    "\n",
    "# Map metadata regarding location\n",
    "df['address_road'] = [x.get('address').get('road') for x in reverse_coords_list]\n",
    "df['concelho'] = [x.get('address').get('town') for x in reverse_coords_list]\n",
    "df['freguesia'] = [x.get('address').get('village') if 'village' in x.get('address') else x.get('address').get('neighbourhood') for x in reverse_coords_list]\n",
    "df['distrito'] = [x.get('address').get('county') for x in reverse_coords_list]\n",
    "\n",
    "# Determine if location is national road, highway or city center\n",
    "df['address_road'] = df['address_road'].fillna('')\n",
    "df['is_national_road'] = df['address_road'].str.contains('EN')\n",
    "df['is_highway'] = df['address_road'].str.contains('Auto')\n",
    "df['is_city_center'] = (~df['is_national_road']) & (~df['is_highway']) & (df['address_road'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "RFZXEvlLJB6Y",
    "outputId": "d1aa5789-ab2f-4a58-e879-aea74613f055"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PanelID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Max_Visibi</th>\n",
       "      <th>Average_Da</th>\n",
       "      <th>coords</th>\n",
       "      <th>address_road</th>\n",
       "      <th>concelho</th>\n",
       "      <th>freguesia</th>\n",
       "      <th>distrito</th>\n",
       "      <th>is_national_road</th>\n",
       "      <th>is_highway</th>\n",
       "      <th>is_city_center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26144</td>\n",
       "      <td>-8.473975</td>\n",
       "      <td>40.900768</td>\n",
       "      <td>69</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[[-8.473975, 40.900768]]</td>\n",
       "      <td>Rua Alto das Casas</td>\n",
       "      <td>São João da Madeira</td>\n",
       "      <td>Macieira de Sarnes</td>\n",
       "      <td>Aveiro</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11714</td>\n",
       "      <td>-9.315949</td>\n",
       "      <td>38.958125</td>\n",
       "      <td>69</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[[-9.315949, 38.958125]]</td>\n",
       "      <td>EN 9</td>\n",
       "      <td>Mafra</td>\n",
       "      <td>Barreiralva</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26109</td>\n",
       "      <td>-8.510079</td>\n",
       "      <td>40.871821</td>\n",
       "      <td>69</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[[-8.510079, 40.871821]]</td>\n",
       "      <td>Rua Professor Doutor António Joaquim Ferreira ...</td>\n",
       "      <td>Oliveira de Azeméis</td>\n",
       "      <td>Vila de Cucujães</td>\n",
       "      <td>Aveiro</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PanelID         X          Y  Max_Visibi  Average_Da  \\\n",
       "0    26144 -8.473975  40.900768          69        31.0   \n",
       "1    11714 -9.315949  38.958125          69        31.0   \n",
       "2    26109 -8.510079  40.871821          69        32.0   \n",
       "\n",
       "                     coords  \\\n",
       "0  [[-8.473975, 40.900768]]   \n",
       "1  [[-9.315949, 38.958125]]   \n",
       "2  [[-8.510079, 40.871821]]   \n",
       "\n",
       "                                        address_road             concelho  \\\n",
       "0                                 Rua Alto das Casas  São João da Madeira   \n",
       "1                                               EN 9                Mafra   \n",
       "2  Rua Professor Doutor António Joaquim Ferreira ...  Oliveira de Azeméis   \n",
       "\n",
       "            freguesia distrito  is_national_road  is_highway  is_city_center  \n",
       "0  Macieira de Sarnes   Aveiro             False       False            True  \n",
       "1         Barreiralva   Lisboa              True       False           False  \n",
       "2    Vila de Cucujães   Aveiro             False       False            True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwX-06T6XuUb"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHq9DYBYXuUb"
   },
   "source": [
    "The next cells present you an exploratory data analysis to give you some insights and/or intuition on the information we extracted before going into a \"very algorithmic\" approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RHYnhQGVJB6Z"
   },
   "outputs": [],
   "source": [
    "def find_neighbours_within_radius(xy, radius):\n",
    "    \"\"\"\n",
    "    This function is used for returning the list of neighbours within a certain radius in a very efficient way.\n",
    "    Inspirations: \n",
    "    \n",
    "    # https://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size/\n",
    "    # https://stackoverflow.com/questions/43592094/efficient-way-to-calculate-geographic-density-in-pandas \n",
    "    # https://stackoverflow.com/questions/34579213/dbscan-for-clustering-of-geographic-location-data \n",
    "    \n",
    "    For instance, between the coordinates (40.900768, -8.473975) and (40.214686, -8.432738) everything is counted as being within a 1.5km\n",
    "        radius. The actual distance between them is 600m, determined using geopy.distance, not shown here.\n",
    "        \n",
    "    Args:\n",
    "        xy (np.ndarray (N, 2)): Numpy array with the coordinates.\n",
    "        radius (float): Radius in km.\n",
    "    \n",
    "    Returns:\n",
    "        List[List[int]]: List of indexes representing the neighbors, for each element of the list.\n",
    "    \"\"\"\n",
    "    tree = cKDTree(xy)\n",
    "    within_radius = tree.query_ball_tree(tree, r=radius)\n",
    "    return within_radius\n",
    "\n",
    "def get_density_billboards(df, radius=1.5):\n",
    "    \"\"\"\n",
    "    Calculate number of billboards in a X km radius for each point.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with list of panels + coordinates.\n",
    "        radius (float): Radius to get density for.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    neighbours_within_radius = find_neighbours_within_radius(\n",
    "        np.radians(df_copy[['Y', 'X']].values), \n",
    "        radius/KMS_PER_RADIAN\n",
    "    )\n",
    "\n",
    "    df_copy['nbr_points_around_billboard'] = [len(x) for x in neighbours_within_radius]\n",
    "\n",
    "    return df_copy, neighbours_within_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5YLm4m8BJB6a"
   },
   "outputs": [],
   "source": [
    "df, neighbours_within_radius = get_density_billboards(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PanelID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Max_Visibi</th>\n",
       "      <th>Average_Da</th>\n",
       "      <th>coords</th>\n",
       "      <th>address_road</th>\n",
       "      <th>concelho</th>\n",
       "      <th>freguesia</th>\n",
       "      <th>distrito</th>\n",
       "      <th>is_national_road</th>\n",
       "      <th>is_highway</th>\n",
       "      <th>is_city_center</th>\n",
       "      <th>nbr_points_around_billboard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26144</td>\n",
       "      <td>-8.473975</td>\n",
       "      <td>40.900768</td>\n",
       "      <td>69</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[[-8.473975, 40.900768]]</td>\n",
       "      <td>Rua Alto das Casas</td>\n",
       "      <td>São João da Madeira</td>\n",
       "      <td>Macieira de Sarnes</td>\n",
       "      <td>Aveiro</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11714</td>\n",
       "      <td>-9.315949</td>\n",
       "      <td>38.958125</td>\n",
       "      <td>69</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[[-9.315949, 38.958125]]</td>\n",
       "      <td>EN 9</td>\n",
       "      <td>Mafra</td>\n",
       "      <td>Barreiralva</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26109</td>\n",
       "      <td>-8.510079</td>\n",
       "      <td>40.871821</td>\n",
       "      <td>69</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[[-8.510079, 40.871821]]</td>\n",
       "      <td>Rua Professor Doutor António Joaquim Ferreira ...</td>\n",
       "      <td>Oliveira de Azeméis</td>\n",
       "      <td>Vila de Cucujães</td>\n",
       "      <td>Aveiro</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PanelID         X          Y  Max_Visibi  Average_Da  \\\n",
       "0    26144 -8.473975  40.900768          69        31.0   \n",
       "1    11714 -9.315949  38.958125          69        31.0   \n",
       "2    26109 -8.510079  40.871821          69        32.0   \n",
       "\n",
       "                     coords  \\\n",
       "0  [[-8.473975, 40.900768]]   \n",
       "1  [[-9.315949, 38.958125]]   \n",
       "2  [[-8.510079, 40.871821]]   \n",
       "\n",
       "                                        address_road             concelho  \\\n",
       "0                                 Rua Alto das Casas  São João da Madeira   \n",
       "1                                               EN 9                Mafra   \n",
       "2  Rua Professor Doutor António Joaquim Ferreira ...  Oliveira de Azeméis   \n",
       "\n",
       "            freguesia distrito  is_national_road  is_highway  is_city_center  \\\n",
       "0  Macieira de Sarnes   Aveiro             False       False            True   \n",
       "1         Barreiralva   Lisboa              True       False           False   \n",
       "2    Vila de Cucujães   Aveiro             False       False            True   \n",
       "\n",
       "   nbr_points_around_billboard  \n",
       "0                           25  \n",
       "1                            9  \n",
       "2                            5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability in Max Visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Max_Visibi\" argument represents the maximum visibility for that billboard. It seems that the variability is very low - 81% of the billboards have a visibility of 69 meters, and 7% of 145 meters. As such, we opted for ignoring this parameter in the below optimization/calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69     0.811621\n",
       "145    0.071506\n",
       "89     0.031111\n",
       "78     0.023572\n",
       "75     0.015407\n",
       "Name: Max_Visibi, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Max_Visibi'].value_counts(normalize=True)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the areas where we have a high amount of billboards on the exact same location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Heatmap - Number of billboards at the exact same coordinate*\n",
    "\n",
    "The heatmap below shows the number of billboards at the exact same coordinate.\n",
    "The center of Lisbon, Porto and Faro are the areas where there are more billbords in the same coordinate (latitude, longitude). \n",
    "These are areas that have a lot of billboards piled up and on both sides of the street.\n",
    "\n",
    "*2. Billboard density*\n",
    "\n",
    "Within the same plot, we are displaying a cluster where you can see the overall billboard density. The displayed number changes whenever you zoom in/out.\n",
    "\n",
    "**Overall conclusions**\n",
    "\n",
    "You can see that there is a higher billboard density in the coast areas, while the interior of Portugal has a lot less billboards.\n",
    "Lisbon and Porto, being large cities, have the highest amount of billboards. They also have more areas where there's a lot of billboards in the exact same (X,Y) coordinates, compared to other cities with less population density.\n",
    "\n",
    "These are the cities where major action needs to be taken!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "Q5q8-NOhJIFF",
    "outputId": "6c692921-e3ad-4e8e-fed0-5dfca0c64b32"
   },
   "outputs": [],
   "source": [
    "n_out = df[[\"X\", \"Y\"]].value_counts().to_frame('n_OutdoorAd').reset_index()\n",
    "\n",
    "m = folium.Map(location=[38.760398,-9.190202], zoom_start=7)\n",
    "\n",
    "steps = 10\n",
    "color_map = cm.linear.YlOrRd_09.scale(0, 1).to_step(steps)\n",
    "gradient_map = defaultdict(dict)\n",
    "for i in range(steps):\n",
    "    gradient_map[1 / steps * i] = color_map.rgb_hex_str(1 / steps * i)\n",
    "\n",
    "\n",
    "heatmap = HeatMap(\n",
    "    list(zip(n_out[\"Y\"], n_out[\"X\"], n_out[\"n_OutdoorAd\"])), gradient = gradient_map, radius=7)\n",
    "\n",
    "color_map.add_to(m)\n",
    "heatmap.add_to(m)\n",
    "FastMarkerCluster(df[['Y', 'X']].values).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the areas where there's higher visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap below shows a representation of the average number of viewers per day. \n",
    "It can be seen that cities like Coimbra/Santarém display regions where there's a high number of billboard views.\n",
    "\n",
    "These are regions where the billboard density is not as high compared to Porto/Lisbon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "K2OgGyuZYG_J",
    "outputId": "d3c38c1e-2517-439f-b2b5-be4075f155cd"
   },
   "outputs": [],
   "source": [
    "mean_Average_Da = df.groupby(['X', 'Y']).agg({'Average_Da': 'mean'}).reset_index()\n",
    "\n",
    "m1 = folium.Map(location=[38.760398,-9.190202], zoom_start=8)\n",
    "\n",
    "heatmap = HeatMap(\n",
    "    list(zip(mean_Average_Da[\"Y\"],mean_Average_Da[\"X\"], mean_Average_Da[\"Average_Da\"])), gradient = gradient_map, radius=7)\n",
    "\n",
    "color_map.add_to(m1)\n",
    "heatmap.add_to(m1)\n",
    "\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0ivYBnuJB6e"
   },
   "source": [
    "## Metaheuristics: Billboard optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4cIO7GiXuUf"
   },
   "source": [
    "We now present you the algorithmic approach used to optimise the outdoor billboard. \n",
    "\n",
    "First, we calculate the average impressions per day for each location - as we might have the same coordinate with more than one billboard, due to overlap of billboards in the same direction of the road and in opposite directions. \n",
    "\n",
    "We start by defining our fitness function by two terms:\n",
    "\n",
    "$f = avgden(df) - sumviews(df) $, where $avgden(df)$ is the average density of outdoor billboard in a given radius, and $sumviews(df)$ is the total sum of average viewers. In this case, our goal is to minimise the average density and maximize the total number of average billboard viewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "iivYlcNFJB6e",
    "outputId": "39730d4d-0c92-46b5-e0de-c3b9362be04a"
   },
   "outputs": [],
   "source": [
    "# Focus on lisbon\n",
    "\n",
    "df_subset = df[df['distrito'] == 'Lisboa'].reset_index()\n",
    "\n",
    "# We might have different impressions for the same coordinate (maybe diff directions of traffic?) so let's average it out\n",
    "\n",
    "MEAN_IMPRESSIONS_PER_COORD = df_subset.groupby(['X', 'Y']).agg(\n",
    "    {'freguesia': 'first',\n",
    "     'distrito': 'first',\n",
    "     'concelho': 'first',\n",
    "     'Average_Da': 'mean'}).reset_index()\n",
    "\n",
    "df_subset = df_subset[['PanelID', 'X', 'Y', 'Max_Visibi', 'Average_Da']]\n",
    "\n",
    "MEAN_IMPRESSIONS_PER_COORD.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OcWX23zRJB6f",
    "outputId": "26af0bef-ec9b-41a2-d810-ba4caa86df00"
   },
   "outputs": [],
   "source": [
    "def fitness(df, density_weight = 1, views_weight = 1/1e6):\n",
    "    \"\"\"\n",
    "    Fitness function, which we want to minimize\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get billboard density\n",
    "    df, _ = get_density_billboards(df)\n",
    "\n",
    "    max_density = df['nbr_points_around_billboard'].mean()\n",
    "    total_number_of_views = df['Average_Da'].sum()\n",
    "    \n",
    "    max_density_loss = max_density*density_weight,\n",
    "    views_loss = -total_number_of_views*views_weight\n",
    "        \n",
    "    # Get changes between original and current solution\n",
    "   # diff_solutions = df_subset[COLS].merge(df[COLS], on=['PanelID'], suffixes=(('', '_new')))\n",
    "   # diff_solutions = diff_solutions[\n",
    "   #     (diff_solutions['X'] != diff_solutions['X_new']) & (diff_solutions['Y'] != diff_solutions['Y_new'])\n",
    "   # ]\n",
    "    \n",
    "   # billboard_amt_loss = diff_solutions.shape[0]*100\n",
    "    \n",
    "    total_loss = views_loss + max_density_loss# + billboard_amt_loss\n",
    "\n",
    "    return total_loss[0], {'avg_density_loss': max_density_loss, 'views_loss': views_loss} #, 'billboard_amt_loss': billboard_amt_loss}\n",
    "\n",
    "fitness(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perturbation Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created two operators for perturbating our solution, by swapping the billboards' location. The new billboards will be placed at fixed coordinates, which are the locations present in `MEAN_IMPRESSIONS_PER_COORD`. Ideally, we would have a list of valid locations/estimation of number of views, but we don't. \n",
    "\n",
    "- Shuffle_Perturbation:  Randomly shuffles a subset of positions in the generated neighbors.\n",
    "- Shuffle_perturbation_with_probs: Shuffles a subset of positions in the generated neighbors according to a given probability, which is given by their viewing density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULE6Jt3HJB6h"
   },
   "outputs": [],
   "source": [
    "def shuffle_perturbation(neighbor, prob=0.1):\n",
    "    \"\"\"\n",
    "    Randomly shuffles a subset of positions in the generated neighbors.\n",
    "\n",
    "    It picks a neighbor and generates a new neighbour with some of its positions shuffled according to a given probability.\n",
    "\n",
    "    Args:\n",
    "        neighbor (pd.DataFrame): Dataframe with the positions for all the Panels.\n",
    "        prob (float): Probability of each region being shuffled.\n",
    "\n",
    "    Returns:\n",
    "        (pd.DataFrame): Shuffled dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy of the neighbor\n",
    "    neighbor_copy = neighbor.copy()\n",
    "    \n",
    "    # Get the length of this neighbor\n",
    "    neighbor_len = len(MEAN_IMPRESSIONS_PER_COORD)\n",
    "    \n",
    "    # Create a mask of the positions that will shuffle\n",
    "    mask = np.random.random_sample((neighbor_len,)) <= prob\n",
    "    mask = np.arange(neighbor_len)[mask]\n",
    "    \n",
    "    # Create a shuffled mask to change within these values\n",
    "    shuffled_mask = mask.copy()\n",
    "    \n",
    "    # Shuffle this mask\n",
    "    np.random.shuffle(shuffled_mask)\n",
    "    \n",
    "    # Create a variable with the coords that will be used to substitute\n",
    "    final_coords = MEAN_IMPRESSIONS_PER_COORD.loc[shuffled_mask]\n",
    "\n",
    "    # Perform the shuffle operation\n",
    "    neighbor_copy.loc[mask, ['X', 'Y', 'Average_Da']] = final_coords[['X', 'Y', 'Average_Da']].values   \n",
    "\n",
    "    return neighbor_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjnRRkXtJB6h"
   },
   "outputs": [],
   "source": [
    "def shuffle_perturbation_with_probs(neighbor, subset_size_perc=0.1):\n",
    "    \"\"\"\n",
    "    Shuffles a subset of positions in the generated neighbors according to a given probability, which is given by their viewing density.\n",
    "    This should give priority to shuffling regions that have high billboard density first.\n",
    "    \n",
    "    It picks a neighbor and generates a new neighbour with some of its positions shuffled.\n",
    "    \n",
    "    Args:\n",
    "        neighbor (pd.DataFrame): Dataframe with the positions for all the Panels.\n",
    "        prob (float): Probability of each region being shuffled.\n",
    "        \n",
    "    Returns:\n",
    "        (pd.DataFrame): Shuffled dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy of the neighbor\n",
    "    neighbor_copy = neighbor.copy()\n",
    "    \n",
    "    # Get the length of this neighbor\n",
    "    neighbor_len = len(MEAN_IMPRESSIONS_PER_COORD)\n",
    "    \n",
    "    # The mask  of positions to shuffle is not random\n",
    "    # We will create a mask with probabilities according to density\n",
    "    _MEAN_IMPRESSIONS_PER_COORD = MEAN_IMPRESSIONS_PER_COORD.copy()\n",
    "    _MEAN_IMPRESSIONS_PER_COORD[\"probs\"] = _MEAN_IMPRESSIONS_PER_COORD[\"Average_Da\"] / _MEAN_IMPRESSIONS_PER_COORD[\"Average_Da\"].sum()\n",
    "    \n",
    "    # Create a list with indices\n",
    "    indices = [i for i in range(neighbor_len)]\n",
    "    # print(len(indices), neighbor_len)\n",
    "    mask = np.random.choice(indices, size=int(subset_size_perc * neighbor_len), replace=True, p=_MEAN_IMPRESSIONS_PER_COORD[\"probs\"].values)\n",
    "    \n",
    "    # Shuffle this mask\n",
    "    shuffled_mask = mask.copy()\n",
    "    \n",
    "    # Shuffle this mask\n",
    "    np.random.shuffle(shuffled_mask)\n",
    "\n",
    "    # Create a variable with the coords that will be used to substitute\n",
    "    final_coords = MEAN_IMPRESSIONS_PER_COORD.loc[shuffled_mask]\n",
    "\n",
    "    # Perform the shuffle operation\n",
    "    neighbor_copy.loc[mask, ['X', 'Y']] = final_coords[['X', 'Y']].values\n",
    "    \n",
    "    return neighbor_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejU62k5kJB6k"
   },
   "source": [
    "### Apply perturbations on the initial solution for a set of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHY68IllJB6k",
    "outputId": "056a43cd-0d5c-4891-c792-8767271427e6",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "best_fitness = np.inf\n",
    "best_solution = df_subset\n",
    "\n",
    "history_of_best_solutions = []\n",
    "\n",
    "for iteration in range(100):\n",
    "    \n",
    "    # Get n random neighbours\n",
    "    neighbors = best_solution\n",
    "    \n",
    "    # Probability of shuffle perturbation\n",
    "    proba = np.random.randint(2)\n",
    "    if proba == 1:\n",
    "        neighbors = shuffle_perturbation(neighbors, 0.02)\n",
    "       \n",
    "    # Probability of balanced perturbation\n",
    "    proba = np.random.randint(2)\n",
    "    if proba == 1:\n",
    "        neighbors = shuffle_perturbation_with_probs(neighbors, 0.02)\n",
    "    \n",
    "    # Convert to list\n",
    "    neighbors = [neighbors]\n",
    "    \n",
    "    # Sanity-check print\n",
    "    print(f\"Nr of possible solutions: {len(neighbors)}.\")\n",
    "    \n",
    "    # Get fitnesses of possible solutions\n",
    "    fitness_neighbours = [fitness(x)[0] for x in neighbors]\n",
    "    \n",
    "    neighbour_lower_fitness_idx = np.argmin(fitness_neighbours)\n",
    "    fitness_neighbour_lower_fitness = fitness_neighbours[neighbour_lower_fitness_idx]\n",
    "    neighbour_lower_fitness = neighbors[neighbour_lower_fitness_idx]\n",
    "    \n",
    "    if fitness_neighbour_lower_fitness < best_fitness:\n",
    "        best_fitness = fitness_neighbour_lower_fitness\n",
    "        best_solution = neighbour_lower_fitness\n",
    "        \n",
    "        history_of_best_solutions.append(best_solution)\n",
    "\n",
    "        print(\"Found a better solution!\")\n",
    "        \n",
    "    print(\"Epoch %d | Fitness %f\" % (iteration, best_fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness(best_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuQ7BiyQJB6l"
   },
   "source": [
    "### How is the new solution different from the previous one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by representing the changes in coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiTaGnASJB6l"
   },
   "outputs": [],
   "source": [
    "COLS = ['PanelID', 'X', 'Y', 'Max_Visibi', 'Average_Da']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jUJPfoAXuUj"
   },
   "outputs": [],
   "source": [
    "# Merge by the PanelID, to see where the new PanelID is placed\n",
    "\n",
    "diff_solutions = df[COLS].merge(best_solution[COLS], on=['PanelID'], suffixes=(('', '_new')))\n",
    "diff_solutions = diff_solutions[\n",
    "    (diff_solutions['X'] != diff_solutions['X_new']) & (diff_solutions['Y'] != diff_solutions['Y_new'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTR-fECxXuUj"
   },
   "outputs": [],
   "source": [
    "# Get location\n",
    "\n",
    "diff_solutions = diff_solutions.merge(MEAN_IMPRESSIONS_PER_COORD[['freguesia', 'concelho', 'distrito', 'X', 'Y']], on=['X', 'Y'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTWbwbBAXuUk"
   },
   "outputs": [],
   "source": [
    "# Get new location metadata\n",
    "\n",
    "diff_solutions = diff_solutions.merge(\n",
    "    MEAN_IMPRESSIONS_PER_COORD[['freguesia', 'concelho', 'distrito', 'X', 'Y']], \n",
    "    left_on=['X_new', 'Y_new'],\n",
    "    right_on=['X', 'Y'],\n",
    "    how='left',\n",
    "    suffixes=(('', '_new'))\n",
    ")\n",
    "\n",
    "# Remove duplicate columns\n",
    "diff_solutions = diff_solutions.loc[:, ~diff_solutions.columns.duplicated()]\n",
    "diff_solutions = diff_solutions.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "wDwkEus-JB6n",
    "outputId": "5b4cc78a-3907-42e6-87e1-a71a0bd02bc9"
   },
   "outputs": [],
   "source": [
    "diff_solutions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLDJMsTJXuUm"
   },
   "source": [
    "### What is the impact of our current solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check both parts of the fitness function.\n",
    "\n",
    "The maximum density in a 1.5km radius reduced from XXXXXXXX to YYYYYYYYY, while the views loss decreased from XXXXXX to YYYYYYYY.\n",
    "This shows that our algorithm is effectively reducing both terms of our loss function: the negative of the total sum of the daily views and the average billboard density.\n",
    "\n",
    "We have proposed the change of XXXX billboards, which leads to an average increase in the daily viewers of ZZZZZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting solution:\", fitness(df_subset)[1])\n",
    "print(\"Best solution:\", fitness(best_solution)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Difference in the average number of daily viewers\", (diff_solutions['Average_Da_new'] - diff_solutions['Average_Da']).mean())\n",
    "print(\"Number of moved billboards\", diff_solutions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that the average fuel consumption of a passenger car is equal to [5.8 liters/100 km](https://zero.ong/automoveis-conheca-as-diferencas-entre-consumos-anunciados-e-reais/) and that the average price of gasoline [is equal to 1.598 euros/liter (data from 24-May-2021)](https://pt.globalpetrolprices.com/Portugal/gasoline_prices/), we can then calculate an estimate of the money spent on billboard transportation.\n",
    "\n",
    "For simplification purposes, let's assume a single car transports each billboard and needs to do a trip in both directions (of course, won't happen in real life). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "2s-IxJIwaPNJ",
    "outputId": "3b0446e8-43f2-4312-b601-32cd6cd5e5bf"
   },
   "outputs": [],
   "source": [
    "def distance_calc(row):\n",
    "    \"\"\"\n",
    "    Calculates the distance in km between two points\n",
    "    \"\"\"\n",
    "    start = (row['Y'], row['X'])\n",
    "    stop = (row['Y_new'], row['X_new'])\n",
    "\n",
    "    return distance(start, stop).kilometers\n",
    "\n",
    "# Calculate distance in km and travel cost per billboard\n",
    "diff_solutions['distance_km'] = diff_solutions.apply(lambda row: distance_calc (row),axis=1)\n",
    "diff_solutions['distance_km_2x'] = diff_solutions['distance_km'] * 2\n",
    "diff_solutions['travel_cost_euros'] = diff_solutions['distance_km_2x'] * 0.058 * 1.598\n",
    "\n",
    "print(\"Total travel cost (€)\", diff_solutions['travel_cost_euros'].sum())\n",
    "\n",
    "tmp = (diff_solutions['Average_Da_new'] - diff_solutions['Average_Da']) / (diff_solutions['travel_cost_euros'])\n",
    "print(\"Number of extra viewers per euro\", tmp.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvb-20m-XuUn",
    "outputId": "98d5be78-8dcb-4d2c-bd79-956b716dd358"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "mask = (~diff_solutions.concelho.isna()) & (~diff_solutions.concelho_new.isna())\n",
    "g = sns.displot(diff_solutions[mask], x=\"concelho\", y=\"concelho_new\", cbar=True)\n",
    "g.set_xticklabels(rotation=50, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I6FNrp5XuUq"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21VJJ_xBXuUq"
   },
   "source": [
    "## Scalability and Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACjLWtfrXuUq"
   },
   "source": [
    "We believe that this optimisation model can be one of the modules of a decision support system that could benefit two distinct stakeholders:\n",
    "\n",
    "**1. Policy-makers (*e.g.* the public management intervenients of the municipalities):**\n",
    "\n",
    "Assuming that most of the billboards are placed in areas (*i.e.*, territory) that concern public management, this kind of model could help decision-makers in the regions that could be given to new market players/entities to place specific billboards. While optimising the quality of life in cities, this could also optimise the management process.\n",
    "\n",
    "**2. Advertising Companies:**\n",
    "\n",
    "Once again, we envision that this model would be integrated into a decision support system that could advise companies on places with good potential that may be underestimated. This way, companies could get a better measure of their competitors and could leverage potential places, thus benefitting/increasing the quality of their investment and helping (at the same time) the sustainable paradigm we intend to implement in cities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advertising Investments\n",
    "In 2017, advertising investments made in outdoor represented 11.7% of the market according to Omnicom data (please refer to [https://obercom.pt/wp-content/uploads/2019/05/Publicidade_2019_Final.pdf](https://obercom.pt/wp-content/uploads/2019/05/Publicidade_2019_Final.pdf)). This percentage is mostly due to the knowledge of the advantages of this type of advertising, such as the great effectiveness in reach (it is a form of advertising without interruption since it remains on display 24 hours a day) and the power to reach different parts of the city, social classes and age groups (please refer to [https://www.adquick.com/blog/what-are-the-benefits-of-outdoor-advertising/](https://www.adquick.com/blog/what-are-the-benefits-of-outdoor-advertising/)).\n",
    "\n",
    "#### Outdoor Advertising Media Coverage\n",
    "A recent study by the company PSE shows that the outdoor advertising media has close to 90% coverage. With the new confinement decreed in January, both coverage and frequency have naturally decreased, resulting in a lower audience production. However, this audience is still high, around 50,000 viewers (please refer to [https://www.meiosepublicidade.pt/2021/02/estudo-audiencias-outdoor-ja-mede-80-cento-dos-suportes-portugal/](https://www.meiosepublicidade.pt/2021/02/estudo-audiencias-outdoor-ja-mede-80-cento-dos-suportes-portugal/)).\n",
    "\n",
    "#### Outdoor Advertising Media Costs\n",
    "The annual corporate outdoor advertising media cost was in 2019, equal to €89 534 (please refer to [https://www.ine.pt/xportal/xmain?xpid=INE&xpgid=ine_indicadores&indOcorrCod=0006846&contexto=bd&selTab=tab2&xlang=PT](https://www.ine.pt/xportal/xmain?xpid=INE&xpgid=ine_indicadores&indOcorrCod=0006846&contexto=bd&selTab=tab2&xlang=PT)). By switching the position of billboards to positions with lower billboard density and higher visibility, we gain X% of the audience. Considering that the average rental cost remains fixed, and assuming that Y people who see it have an interest in the brand, there is an impact K times greater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Cb4ehklXuUr"
   },
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWleGkzWXuUr"
   },
   "source": [
    "It would be interesting to have information related to:\n",
    "\n",
    " - Distribution of the billboards per company (the concession): with this data, we could optimise our algorithm by taking into account the distribution of billboards in a given radius per company (*i.e.*, ideally, we want the billboards to be uniformly distributed along that area).\n",
    "\n",
    " - Actual billboard coverage in the dataset: this data would help us to refine the optimisation algorithm since we could create a different restriction in the fitness function (*e.g.*, we do not want to minimise the billboard coverage in the dataset, therefore, the best solution, could not be created by neighbours that would \"contain\" this issue)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deliverable.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
